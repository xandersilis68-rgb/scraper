name: Volleyball Scraper

on:
  schedule:
    - cron: '0 * * * *' # Every hour at minute 0
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # 1. Checkout the repo
      - uses: actions/checkout@v4

      # 2. Set up Python 3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # 3. Install Python dependencies
      - run: pip install --upgrade pip
      - run: pip install selenium pandas

      # 4. Display Chrome version (for debugging)
      - name: Show Chrome version
        run: google-chrome --version || true

      # 5. Install ChromeDriver that matches the installed Chrome
      - name: Install matching ChromeDriver
        run: |
          set -e
          echo "Detecting Chrome version..."
          if ! command -v google-chrome >/dev/null 2>&1; then
            echo "google-chrome not found in PATH; trying google-chrome-stable"
            CHROME_CMD=google-chrome-stable
          else
            CHROME_CMD=google-chrome
          fi
          CHROME_VERSION_FULL=$($CHROME_CMD --version | sed -E 's/.* ([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+).*/\1/')
          echo "Chrome full version: $CHROME_VERSION_FULL"
          CHROME_MAJOR=$(echo "$CHROME_VERSION_FULL" | cut -d. -f1)
          echo "Chrome major version: $CHROME_MAJOR"
          LATEST=$(curl -sS https://chromedriver.storage.googleapis.com/LATEST_RELEASE_$CHROME_MAJOR)
          if [ -z "$LATEST" ]; then
            echo "Failed to find chromedriver for major version $CHROME_MAJOR"
            exit 1
          fi
          echo "Installing chromedriver version: $LATEST"
          curl -sS -O "https://chromedriver.storage.googleapis.com/${LATEST}/chromedriver_linux64.zip"
          unzip -q chromedriver_linux64.zip
          sudo mv -f chromedriver /usr/local/bin/chromedriver
          sudo chmod +x /usr/local/bin/chromedriver
          rm chromedriver_linux64.zip
          echo "chromedriver installed: $(/usr/local/bin/chromedriver --version)"

      # 6. Run scraper
      - name: Run scraper
        run: python scraper.py

      # 7. Upload results
      - uses: actions/upload-artifact@v4
        with:
          name: volleyball_players_efficiency
          path: volleyball_players_efficiency.csv
