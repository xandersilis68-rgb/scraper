name: Volleyball Scraper

on:
  schedule:
    - cron: '0 * * * *'   # every hour at minute 0
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Install dependencies
      run: |
        pip install selenium pandas
        wget https://chromedriver.storage.googleapis.com/117.0.5938.62/chromedriver_linux64.zip
        unzip chromedriver_linux64.zip
        mv chromedriver linux_chromedriver
        chmod +x linux_chromedriver

    - name: Run scraper
      env:
        PATH: ${{ github.workspace }}:${{ env.PATH }}
      run: |
        export CHROMEDRIVER_PATH=${{ github.workspace }}/linux_chromedriver
        python scraper.py

    - name: Upload results
      uses: actions/upload-artifact@v3
      with:
        name: volleyball_players_efficiency
        path: volleyball_players_efficiency.csv
